{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "text_analysis (1).ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYIy09D6Awc_"
      },
      "source": [
        "## Import important libraries \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RECqMisxAwdC",
        "outputId": "a256ce96-1ad9-4a71-d6f0-2bee3fe87abe"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os \n",
        "import glob\n",
        "import time \n",
        "import re\n",
        "import nltk\n",
        "from collections import Counter\n",
        "from string import punctuation\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tag import StanfordPOSTagger\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt')\n",
        "nltk.download(\"averaged_perceptron_tagger\") \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/kidist/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /home/kidist/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcZKG2zyAwdE"
      },
      "source": [
        "## load the dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdwz8GpJAwdF"
      },
      "source": [
        "# Get all file path \n",
        "\n",
        "path = 'Health-Tweets'\n",
        "all_files = glob.glob(path + \"/*.txt\")\n",
        "# read dataset \n",
        "df_all = []\n",
        "for filename in all_files:\n",
        "    df= pd.read_csv(filename,sep='|',header=None,error_bad_lines=False,encoding=\"iso-8859-15\",warn_bad_lines=False)\n",
        "    df_all.append(df)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k1mkYF7AwdF",
        "outputId": "983fa7af-49da-4c74-8251-0b76030360af"
      },
      "source": [
        "# merge all dataframes into a single dataframe\n",
        "merged_df = pd.concat(df_all, axis=0, ignore_index=True)\n",
        "merged_df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Int64Index([0, 1, 2], dtype='int64')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_2KXaa3AwdG",
        "outputId": "8fa31b2a-b42b-4a55-844a-ac08209d871d"
      },
      "source": [
        "# rename the columns name\n",
        "merged_df.columns=[\"user_id\",\"date\",\"tweet\"]\n",
        "merged_df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['user_id', 'date', 'tweet'], dtype='object')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsVDMC6EAwdG",
        "outputId": "9277869b-fe01-4014-fcff-5dc8fcbf2756"
      },
      "source": [
        "merged_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>date</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>586282503981375488</td>\n",
              "      <td>Thu Apr 09 21:40:16 +0000 2015</td>\n",
              "      <td>Los Angeles closes 500 medical marijuana shops...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>586278524748750848</td>\n",
              "      <td>Thu Apr 09 21:24:27 +0000 2015</td>\n",
              "      <td>U.S. cuts poultry export forecast as deadly bi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>586273441801699328</td>\n",
              "      <td>Thu Apr 09 21:04:15 +0000 2015</td>\n",
              "      <td>Fears over Roundup herbicide residues prompt p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>586254712523096068</td>\n",
              "      <td>Thu Apr 09 19:49:50 +0000 2015</td>\n",
              "      <td>Liberia watchdog says some Ebola funds unaccou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>586243976333787137</td>\n",
              "      <td>Thu Apr 09 19:07:10 +0000 2015</td>\n",
              "      <td>Diabetes devices may interfere with avalanche ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              user_id                            date  \\\n",
              "0  586282503981375488  Thu Apr 09 21:40:16 +0000 2015   \n",
              "1  586278524748750848  Thu Apr 09 21:24:27 +0000 2015   \n",
              "2  586273441801699328  Thu Apr 09 21:04:15 +0000 2015   \n",
              "3  586254712523096068  Thu Apr 09 19:49:50 +0000 2015   \n",
              "4  586243976333787137  Thu Apr 09 19:07:10 +0000 2015   \n",
              "\n",
              "                                               tweet  \n",
              "0  Los Angeles closes 500 medical marijuana shops...  \n",
              "1  U.S. cuts poultry export forecast as deadly bi...  \n",
              "2  Fears over Roundup herbicide residues prompt p...  \n",
              "3  Liberia watchdog says some Ebola funds unaccou...  \n",
              "4  Diabetes devices may interfere with avalanche ...  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTjQVZ8GAwdH",
        "outputId": "f3eb3923-4ee1-4105-e175-c8de225423e8"
      },
      "source": [
        "merged_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(62817, 3)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4Lhhh-WAwdH"
      },
      "source": [
        "The total number of tweets in the dataset is 62817"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzFiinOpAwdH"
      },
      "source": [
        "## Split the texts into monthly  intervals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vHgwWvtAwdI"
      },
      "source": [
        "#  Convert string date to Datetime objects\n",
        "merged_df['date'] = pd.to_datetime(merged_df['date'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbNU2J3OAwdI",
        "outputId": "ffe31fae-c747-4559-ae6c-57cd5304beea"
      },
      "source": [
        "# Create new column month-year. This will be used to split the data into monthly interval\n",
        "def get_month_and_year(x):\n",
        "    return \"{}-{}\".format(x.month,x.year)\n",
        "merged_df[\"month-year\"] = merged_df[\"date\"].apply(get_month_and_year)\n",
        "merged_df[\"tweet\"][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Los Angeles closes 500 medical marijuana shops, but hundreds remain http://reut.rs/1CvkXmm'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZn6bc3tAwdI",
        "outputId": "40f2f724-f9f6-4201-80c7-41a532e26ae8"
      },
      "source": [
        "# remove the tweet URL , number ,and username, because this items will not provide useful information. Specially\n",
        "# numbers increase the number of unique words without any  siginificant gain in the information\n",
        "def remove_url_num_uname(text):\n",
        "    output = re.sub('http[s]?://\\S+', '', text) \n",
        "    output = re.sub(\"\\.{2,}\",\"\",output)\n",
        "    output = re.sub('@[^\\s]+','',output)\n",
        "    output= re.sub(\"[^a-zA-Z]+\",\" \", output)\n",
        "    return output\n",
        "         \n",
        "\n",
        "merged_df[\"tweet\"]= merged_df[\"tweet\"].apply(remove_url_num_uname)\n",
        "merged_df[\"tweet\"][0]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Los Angeles closes medical marijuana shops but hundreds remain '"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDZ3tGpwAwdJ",
        "outputId": "ea0e90a7-d436-4a0d-d5dc-4880306c6c7d"
      },
      "source": [
        "# group the dataframe into monthly interval\n",
        "months_df = list(merged_df.groupby(\"month-year\"))\n",
        "months_df[21]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('3-2013',\n",
              "                   user_id                      date  \\\n",
              " 7619   318416481232769024 2013-03-31 17:36:19+00:00   \n",
              " 7620   318311103203520512 2013-03-31 10:37:35+00:00   \n",
              " 7621   318199451233693697 2013-03-31 03:13:55+00:00   \n",
              " 7622   318092722751823872 2013-03-30 20:09:49+00:00   \n",
              " 7623   318062748787417088 2013-03-30 18:10:43+00:00   \n",
              " ...                   ...                       ...   \n",
              " 50847  307555197092249600 2013-03-01 18:17:27+00:00   \n",
              " 50848  307554254913163264 2013-03-01 18:13:43+00:00   \n",
              " 50849  307553650211946497 2013-03-01 18:11:18+00:00   \n",
              " 50850  307537038373179393 2013-03-01 17:05:18+00:00   \n",
              " 50851  307536712463159296 2013-03-01 17:04:00+00:00   \n",
              " \n",
              "                                                    tweet month-year  \n",
              " 7619   Today s getfit tip We firmly believe that choc...     3-2013  \n",
              " 7620               Girl tackles marathons on continents      3-2013  \n",
              " 7621               It s FILTHY and lives in your wallet      3-2013  \n",
              " 7622   Today s getfit tip Reached your goal weight Ge...     3-2013  \n",
              " 7623   KISS Paul Stanley I m deaf in one ear humanfactor     3-2013  \n",
              " ...                                                  ...        ...  \n",
              " 50847  Bracing for cuts one hospital exec says We Nee...     3-2013  \n",
              " 50848  Facebook Yelp users do good job of measuring h...     3-2013  \n",
              " 50849         Today s cartoon Beware the first of March      3-2013  \n",
              " 50850  Today s headlines Health Law Implementation Li...     3-2013  \n",
              " 50851   runs down the sequester bite on medical resea...     3-2013  \n",
              " \n",
              " [1124 rows x 4 columns])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrzgjwhVAwdJ",
        "outputId": "34027c7a-4ca4-4bee-912f-33001f133826"
      },
      "source": [
        "len(months_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "47"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOj0dPfZAwdJ"
      },
      "source": [
        "There are 47 months in the five years of data. This shows that some of the months are missing. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c00QbI-eAwdK"
      },
      "source": [
        "## Text preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXaBOgIgAwdK"
      },
      "source": [
        "# sentence tokenization function \n",
        "def get_tokens(text):\n",
        "    return word_tokenize(text)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls57hqOGAwdK"
      },
      "source": [
        "# apply word toknization \n",
        "for month,month_df in months_df:\n",
        "    month_df[\"tokens\"] =  month_df[\"tweet\"].apply(get_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXbEoEJkAwdK",
        "outputId": "6d50f176-7c16-4ed4-ae95-06fe2181bfca"
      },
      "source": [
        "months_df[0][1].iloc[0][\"tokens\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['For', 'Kids', 'Laughter', 'Really', 'May', 'Be', 'the', 'Best', 'Medicine']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UeA1BrvAwdL"
      },
      "source": [
        "# function to remove stop words, panctuation , and empty string and lowercasing\n",
        "stoplist = set(stopwords.words('english') + list(punctuation))\n",
        "def remove_stopwords(tokens):\n",
        "    output = []\n",
        "    for word in tokens:\n",
        "        if word not in stoplist and word.strip() != \"\":\n",
        "            output.append(word.strip().lower())\n",
        "    return output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh69F2TZAwdL"
      },
      "source": [
        "# remove stop words, panctuation , and empty string and lowercasing\n",
        "for month,month_df in months_df:\n",
        "    month_df[\"tokens\"] =  month_df[\"tokens\"].apply(remove_stopwords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f78LlqyAwdM",
        "outputId": "e8996738-53ed-4368-cb83-51998e8abdfb"
      },
      "source": [
        "months_df[0][1].iloc[0][\"tokens\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['for', 'kids', 'laughter', 'really', 'may', 'be', 'best', 'medicine']"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e25uRFhbAwdM"
      },
      "source": [
        "#  Building the POS mapper for token tags\n",
        "from nltk.corpus.reader.wordnet import VERB, NOUN, ADJ, ADV\n",
        "dict_pos_map = {\n",
        "    # Look for NN in the POS tag because all nouns begin with NN\n",
        "    'NN': NOUN,\n",
        "    'VB':VERB,\n",
        "    'JJ' : ADJ,\n",
        "    'RB':ADV,\n",
        "    'VBG':VERB\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5odFZWUOAwdM",
        "outputId": "c9fc718e-107c-45d0-dcd3-9e2c1ca60c2a"
      },
      "source": [
        "# getting pos information\n",
        "nltk.pos_tag(months_df[0][1].iloc[0][\"tokens\"]) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('for', 'IN'),\n",
              " ('kids', 'NNS'),\n",
              " ('laughter', 'RBR'),\n",
              " ('really', 'RB'),\n",
              " ('may', 'MD'),\n",
              " ('be', 'VB'),\n",
              " ('best', 'JJS'),\n",
              " ('medicine', 'NN')]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_MYuwEHAwdN"
      },
      "source": [
        " # word lemitization function\n",
        "def lemmitize_tokens(tokens):\n",
        "    t = WordNetLemmatizer()\n",
        "    outputs = []\n",
        "    for word,pos in nltk.pos_tag(tokens):\n",
        "        if pos in dict_pos_map:\n",
        "            lemmatized_word = t.lemmatize(word, pos= dict_pos_map[pos])\n",
        "            outputs.append(lemmatized_word)\n",
        "        else:\n",
        "            outputs.append(t.lemmatize(word))\n",
        "    return outputs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZyLAXKjAwdN"
      },
      "source": [
        "# applay word lematization \n",
        "for month,month_df in months_df:\n",
        "    month_df[\"lemm_tokens\"] =  month_df[\"tokens\"].apply(lemmitize_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-9gVqh7AwdN",
        "outputId": "f2a29f19-9e2c-46dc-fa96-78218ce1c5fb"
      },
      "source": [
        "months_df[0][1].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>date</th>\n",
              "      <th>tweet</th>\n",
              "      <th>month-year</th>\n",
              "      <th>tokens</th>\n",
              "      <th>lemm_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>32996</th>\n",
              "      <td>164481705472831488</td>\n",
              "      <td>2012-01-31 22:54:29+00:00</td>\n",
              "      <td>For Kids Laughter Really May Be the Best Medic...</td>\n",
              "      <td>1-2012</td>\n",
              "      <td>[for, kids, laughter, really, may, be, best, m...</td>\n",
              "      <td>[for, kid, laughter, really, may, be, best, me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32997</th>\n",
              "      <td>164463284714610690</td>\n",
              "      <td>2012-01-31 21:41:17+00:00</td>\n",
              "      <td>FDA OKs Drug That Targets Rare Form of Cystic ...</td>\n",
              "      <td>1-2012</td>\n",
              "      <td>[fda, oks, drug, that, targets, rare, form, cy...</td>\n",
              "      <td>[fda, ok, drug, that, target, rare, form, cyst...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32998</th>\n",
              "      <td>164463283489878018</td>\n",
              "      <td>2012-01-31 21:41:17+00:00</td>\n",
              "      <td>Second Breast Cancer Surgery Sometimes Needed</td>\n",
              "      <td>1-2012</td>\n",
              "      <td>[second, breast, cancer, surgery, sometimes, n...</td>\n",
              "      <td>[second, breast, cancer, surgery, sometimes, n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32999</th>\n",
              "      <td>164463282210611200</td>\n",
              "      <td>2012-01-31 21:41:16+00:00</td>\n",
              "      <td>Alternative to Colonoscopy Spots Cancers Too</td>\n",
              "      <td>1-2012</td>\n",
              "      <td>[alternative, colonoscopy, spots, cancers, too]</td>\n",
              "      <td>[alternative, colonoscopy, spot, cancer, too]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33000</th>\n",
              "      <td>164463280943939587</td>\n",
              "      <td>2012-01-31 21:41:16+00:00</td>\n",
              "      <td>Fatty Diet Before Pregnancy Linked to Gestatio...</td>\n",
              "      <td>1-2012</td>\n",
              "      <td>[fatty, diet, before, pregnancy, linked, gesta...</td>\n",
              "      <td>[fatty, diet, before, pregnancy, linked, gesta...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  user_id                      date  \\\n",
              "32996  164481705472831488 2012-01-31 22:54:29+00:00   \n",
              "32997  164463284714610690 2012-01-31 21:41:17+00:00   \n",
              "32998  164463283489878018 2012-01-31 21:41:17+00:00   \n",
              "32999  164463282210611200 2012-01-31 21:41:16+00:00   \n",
              "33000  164463280943939587 2012-01-31 21:41:16+00:00   \n",
              "\n",
              "                                                   tweet month-year  \\\n",
              "32996  For Kids Laughter Really May Be the Best Medic...     1-2012   \n",
              "32997  FDA OKs Drug That Targets Rare Form of Cystic ...     1-2012   \n",
              "32998     Second Breast Cancer Surgery Sometimes Needed      1-2012   \n",
              "32999      Alternative to Colonoscopy Spots Cancers Too      1-2012   \n",
              "33000  Fatty Diet Before Pregnancy Linked to Gestatio...     1-2012   \n",
              "\n",
              "                                                  tokens  \\\n",
              "32996  [for, kids, laughter, really, may, be, best, m...   \n",
              "32997  [fda, oks, drug, that, targets, rare, form, cy...   \n",
              "32998  [second, breast, cancer, surgery, sometimes, n...   \n",
              "32999    [alternative, colonoscopy, spots, cancers, too]   \n",
              "33000  [fatty, diet, before, pregnancy, linked, gesta...   \n",
              "\n",
              "                                             lemm_tokens  \n",
              "32996  [for, kid, laughter, really, may, be, best, me...  \n",
              "32997  [fda, ok, drug, that, target, rare, form, cyst...  \n",
              "32998  [second, breast, cancer, surgery, sometimes, n...  \n",
              "32999      [alternative, colonoscopy, spot, cancer, too]  \n",
              "33000  [fatty, diet, before, pregnancy, linked, gesta...  "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q94Dy_1lAwdO",
        "outputId": "f14cec5b-50a2-4550-a41f-1504526869fc"
      },
      "source": [
        "months_df[1][1].iloc[5][\"tokens\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['tv', 'ads', 'may', 'drinking', 'children', 'drink']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PusAYz62AwdO",
        "outputId": "ed3e1e26-c72f-4475-b093-251d91988910"
      },
      "source": [
        "months_df[1][1].iloc[5][\"lemm_tokens\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['tv', 'ad', 'may', 'drink', 'child', 'drink']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tjuq-tamAwdO"
      },
      "source": [
        "## Unigram language model for every month"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYG75pTpAwdO"
      },
      "source": [
        "# function to builed word count for each month  and find total number of words occurrence \n",
        "\n",
        "def build_word_count(tokens):\n",
        "    word_count = Counter()\n",
        "    total_word_count = 0\n",
        "    for li in tokens:\n",
        "        total_word_count +=len(li)\n",
        "        word_count.update(li)\n",
        "    return dict(word_counts = word_count,total = total_word_count)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isxvTvzdAwdO"
      },
      "source": [
        "months_words_count = dict() # Frequency of words in a month.\n",
        "for month,month_df in months_df:\n",
        "    counts = build_word_count(month_df[\"lemm_tokens\"])\n",
        "    months_words_count[month]= counts\n",
        "     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPzpqJrkAwdP"
      },
      "source": [
        "# for each month compute the probavlities of each word \n",
        "def compute_prob(word_counts,total):\n",
        "    return { word:count/total for word,count in word_counts.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ow1uPmzAwdP"
      },
      "source": [
        "# get the probablity of each words of the months \n",
        "months_words_prob = dict()\n",
        "for month,month_words_count in months_words_count.items():\n",
        "    probs = compute_prob(**month_words_count)\n",
        "    months_words_prob[month]= probs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRYE078GAwdP"
      },
      "source": [
        "# unigram model\n",
        "class UnigramLangugeModel:\n",
        "    def __init__(self,month_words_prob):\n",
        "        self.words =list( month_words_prob.keys())\n",
        "        self.probs = list(month_words_prob.values())\n",
        "        self.words_prob = month_words_prob\n",
        "    def generate_word(self):\n",
        "        return np.random.choice(self.words, p = self.probs)\n",
        "    def generate_sentence(self,n):\n",
        "        return \" \".join([self.generate_word() for i in range(n)])\n",
        "    def get_word_prob(self,word):\n",
        "        if not word in self.words_prob:\n",
        "            return 0\n",
        "        return self.words_prob[word]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCKxnELOAwdP",
        "outputId": "2748d283-c3f6-49d2-f96c-63c1beffc555"
      },
      "source": [
        "months_words_prob.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['1-2012', '1-2013', '1-2014', '1-2015', '10-2011', '10-2012', '10-2013', '10-2014', '11-2011', '11-2012', '11-2013', '11-2014', '12-2011', '12-2012', '12-2013', '12-2014', '2-2012', '2-2013', '2-2014', '2-2015', '3-2012', '3-2013', '3-2014', '3-2015', '4-2012', '4-2013', '4-2014', '4-2015', '5-2012', '5-2013', '5-2014', '6-2011', '6-2012', '6-2013', '6-2014', '7-2011', '7-2012', '7-2013', '7-2014', '8-2011', '8-2012', '8-2013', '8-2014', '9-2011', '9-2012', '9-2013', '9-2014'])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrDPfNkSAwdQ"
      },
      "source": [
        "model = UnigramLangugeModel(months_words_prob[\"1-2015\"]) # Unigram model for January 2015 data.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esINWO7UAwdQ",
        "outputId": "c153c41b-4047-4e82-f08c-8cc3f4691217"
      },
      "source": [
        "model.generate_word() # Generate single word using the Unigram model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'meningitis'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TezoBXGkAwdQ",
        "outputId": "c0e1bdcc-2587-4adb-cc77-96585c1189a7"
      },
      "source": [
        "model.generate_sentence(100) # Generate sentence with 100 words using the unigram model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'absolutely better opportunity disease exhaustion drink totally host take never house health notice apnea lab amp lead improve many danger say curly survivor complicated usntechchat dehydration pot medical amp adorable save success she bone mcdonald spill flu see safety please rt but health kind whole reason researcher rt outlive icm should take rt what inspired public truly aleppo say come i plea case glimpse time well nut call test drug appear see is donate how outbreak california privatisation child astrazeneca treatment chili check hard amgen hold care nh breast the clock a virus docs case e call make make pm'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ5vXaFPAwdQ"
      },
      "source": [
        "# Building unigram model for each month \n",
        "lang_models = dict()\n",
        "for month,month_words_count in months_words_count.items():\n",
        "    model = UnigramLangugeModel(months_words_prob[month])\n",
        "    lang_models[month]= model\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_tBwQ5bAwdQ",
        "outputId": "1fc13618-7bc2-406a-a2df-429e9061cab3"
      },
      "source": [
        "lang_models.keys()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['1-2012', '1-2013', '1-2014', '1-2015', '10-2011', '10-2012', '10-2013', '10-2014', '11-2011', '11-2012', '11-2013', '11-2014', '12-2011', '12-2012', '12-2013', '12-2014', '2-2012', '2-2013', '2-2014', '2-2015', '3-2012', '3-2013', '3-2014', '3-2015', '4-2012', '4-2013', '4-2014', '4-2015', '5-2012', '5-2013', '5-2014', '6-2011', '6-2012', '6-2013', '6-2014', '7-2011', '7-2012', '7-2013', '7-2014', '8-2011', '8-2012', '8-2013', '8-2014', '9-2011', '9-2012', '9-2013', '9-2014'])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vJwddYnAwdR",
        "outputId": "830c851f-1e45-4782-9658-b103914cc193"
      },
      "source": [
        "lang_models[\"1-2012\"].generate_word()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'be'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcnnoZxHAwdR"
      },
      "source": [
        "## Calculate KL-divergence for these models and build pairwise representation \n",
        "\n",
        "![image.png](attachment:image.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ldx49VTHAwdR"
      },
      "source": [
        "### Comparing two models' probablities "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFLwsKKFAwdR"
      },
      "source": [
        "model_1= lang_models[\"1-2012\"]\n",
        "model_2 = lang_models[\"1-2013\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOoScMm0AwdR",
        "outputId": "c754a626-968d-4a7f-d9f1-417d0ce58a54"
      },
      "source": [
        "model_1.get_word_prob(\"made\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.000231000231000231"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsrn4sKzAwdS",
        "outputId": "0879b1c5-b642-4513-ac23-c79c9ad5b4eb"
      },
      "source": [
        "model_2.get_word_prob(\"made\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0003774297037176826"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dh64iXGbAwdS"
      },
      "source": [
        "### Computing KL divergance between two models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okQPTV5BAwdS"
      },
      "source": [
        "def kl_divergence(p,q):\n",
        "    dkl = p*np.log(p/q)\n",
        "    return dkl\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVRjePrGAwdS"
      },
      "source": [
        "def dkl(model_1,model_2):\n",
        "    output  = 0\n",
        "    for word in model_1.words:\n",
        "        p = model_1.get_word_prob(word)\n",
        "        q = model_2.get_word_prob(word)\n",
        "        if q != 0:\n",
        "            output += kl_divergence(p,q)     \n",
        "        \n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "op7V7dIfAwdS",
        "outputId": "542accce-fe51-4788-dab1-4fd7de785116"
      },
      "source": [
        "dkl(model_1,model_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6614172253206011"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8azRuq7AwdT"
      },
      "source": [
        "## Building pairwise matrix from the KL divergance result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SORUPxqAwdT"
      },
      "source": [
        "months = list(lang_models.keys())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skUuTMvtAwdT",
        "outputId": "f6f12a8a-c5ff-46c5-8341-7c8b6c06a2ea"
      },
      "source": [
        "pairwise_matrix = np.zeros((len(months),len(months)))\n",
        "pairwise_matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkW_4SyvAwdT"
      },
      "source": [
        "for i in range(len(months)):\n",
        "    for j in range(len(months)):\n",
        "        pairwise_matrix[i,j] = dkl(lang_models[months[i]],lang_models[months[j]])\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ph7bq5-0AwdU",
        "outputId": "8a3e423c-1160-4920-9392-809a30f7dc74"
      },
      "source": [
        "print(pairwise_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.         0.66141723 0.54392037 ... 0.28811025 0.46907418 0.73865714]\n",
            " [0.17912045 0.         0.30464566 ... 0.08876156 0.29059466 0.54169743]\n",
            " [0.12466507 0.37233368 0.         ... 0.10370461 0.11522305 0.32437324]\n",
            " ...\n",
            " [0.21528997 0.47138389 0.42181024 ... 0.         0.34383827 0.64964065]\n",
            " [0.16977653 0.47127292 0.22854255 ... 0.12713369 0.         0.43425258]\n",
            " [0.04152094 0.31527176 0.07992819 ... 0.15347459 0.07469613 0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIk_B9RgAwdU"
      },
      "source": [
        "## Finding most added or removed words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuFPcP5HAwdU"
      },
      "source": [
        "On average if a words was most added or removed from  month to month it will have higher variance. Here I will use standard deviation to find most variying words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7CcPmy8AwdU"
      },
      "source": [
        "# find unique words \n",
        "uniq_words = set()\n",
        "for month in months :\n",
        "    uniq_words.update(lang_models[month].words)\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDmNKQI7AwdU"
      },
      "source": [
        "uniq_words = list(uniq_words)\n",
        "uniq_words.sort()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Hgio_YnAwdV",
        "outputId": "14a528e7-6dc5-4dc8-a70e-1379265d776c"
      },
      "source": [
        "len(uniq_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "22084"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pcd_fz93AwdV",
        "outputId": "aa435e54-77b0-42ff-a67c-9d659ebf56f5"
      },
      "source": [
        "months_all_words_count = np.zeros((len(uniq_words),len(months)))\n",
        "months_all_words_count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YIKowE1AwdV"
      },
      "source": [
        "for i in range(len(uniq_words)):\n",
        "    for j in range(len(months)):\n",
        "        if uniq_words[i] in months_words_count[months[j]][\"word_counts\"]:\n",
        "            months_all_words_count[i,j] = months_words_count[months[j]][\"word_counts\"][uniq_words[i]]\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1ZLgu8bAwdV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfRTisiDAwdV"
      },
      "source": [
        "words_stds = months_all_words_count.std(axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWs78bK0AwdW"
      },
      "source": [
        "topk = words_stds[words_stds.argsort()[-3:]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WA7VcmAAwdW",
        "outputId": "eb897eaf-29ed-40b7-d582-b061ef399792"
      },
      "source": [
        "topk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 90.92331075, 173.79803351, 288.76498862])"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoy8kuJnAwdW",
        "outputId": "2a552479-3085-44d2-9029-d5f46fffaf37"
      },
      "source": [
        "words_stds.max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "288.7649886169951"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HztiIbQMAwdW",
        "outputId": "5bfb235d-6c85-4e64-bfd0-26af602e5335"
      },
      "source": [
        "months_all_words_count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 10., 242., 102., ...,  21.,  73., 174.],\n",
              "       [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
              "       ...,\n",
              "       [  1.,   2.,   0., ...,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0., ...,   0.,   0.,   0.]])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNz-S9qfAwdW",
        "outputId": "4cc41920-2be6-411a-ea92-6ad4db138fd1"
      },
      "source": [
        "words_stds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([71.75456129,  0.20184751,  0.14430489, ...,  0.54494674,\n",
              "        0.20184751,  0.14430489])"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gyhpYvgAwdX"
      },
      "source": [
        "uniq_words = np.array(uniq_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ll0JxwiVAwdX",
        "outputId": "9a7e7137-452d-40bd-ce86-a223df416092"
      },
      "source": [
        "uniq_words[words_stds.argsort()[-30:]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['year', 'cancer', 'well', 'make', 'to', 'doctor', 'care', 'via',\n",
              "       'today', 'may', 'nhs', 'how', 'hospital', 'food', 'drug', 'get',\n",
              "       'nh', 's', 'q', 'amp', 'patient', 'say', 'new', 'u', 'the', 'a',\n",
              "       'health', 'healthtalk', 'rt', 'ebola'], dtype='<U38')"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3_b5WxFAwdX",
        "outputId": "3f467689-9c87-4462-ae6f-fadf57e041a3"
      },
      "source": [
        "words_stds[words_stds.argsort()[-30:]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 32.3405935 ,  32.34301501,  32.83351698,  32.91186084,\n",
              "        33.10900826,  33.37950025,  33.79123991,  33.84435656,\n",
              "        34.81225595,  35.46934228,  37.1933638 ,  37.78924664,\n",
              "        39.85211458,  45.09747001,  46.51583549,  47.30085365,\n",
              "        49.4313705 ,  49.65235412,  51.04128048,  51.11979203,\n",
              "        53.29773219,  58.37271171,  65.34973987,  65.75797566,\n",
              "        66.40850573,  71.75456129,  87.36493553,  90.92331075,\n",
              "       173.79803351, 288.76498862])"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9LcmxEdAwdY"
      },
      "source": [
        "As it can be seen here the top varying words are `ebola`, `rt`, `healthtalk`, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDgIUCVnAwdY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}